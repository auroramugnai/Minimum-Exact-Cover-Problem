{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Solving MECP with QAOA+ using \"Parameter Fixing\" technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils_to_build_QAOAAnsatz import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
    "from qiskit.primitives import StatevectorEstimator, StatevectorSampler\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = get_parameters_from_user() \n",
    "\n",
    "# Get the parameters separately\n",
    "chosen_instances = params['chosen_instances']\n",
    "chosen_k = params['chosen_k']\n",
    "max_p = params['p']\n",
    "random_attempts = params['random_attempts']\n",
    "init_string = params['init_string']\n",
    "n = params['n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define k.\n",
    "def round_up(n, decimals=0):\n",
    "    multiplier = 10**decimals\n",
    "    return math.ceil(n * multiplier) / multiplier  \n",
    "\n",
    "k_dict = {'L=n': [0.3333333333333333,   0.5,   0.5,   0.3333333333333333,   0.5,   0.5,   0.5,   \n",
    "                  0.3333333333333333,   0.25,   0.25],\n",
    "          'L=max(L_EC)': [0.16666666666666666,   0.16666666666666666,   0.25,   0.16666666666666666,  \n",
    "                          0.3333333333333333, 0.25,   0.25,   0.16666666666666666,   0.08333333333333333,  \n",
    "                          0.08333333333333333],\n",
    "          'L=L_MEC': [0.16666666666666666,   0.16666666666666666,   0.16666666666666666,\n",
    "                      0.1111111111111111,   0.16666666666666666,   0.16666666666666666,   0.25,   \n",
    "                      0.16666666666666666,  0.08333333333333333,   0.08333333333333333]}\n",
    "\n",
    "# Arrotondo per eccesso\n",
    "k_dict_new = {}\n",
    "for key,value_list in k_dict.items():\n",
    "    k_dict_new[key] = [round_up(v, 3) for v in value_list]\n",
    "k_dict_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## For Every Instance Chosen, Do the Minimization\n",
    "\n",
    "This section runs the **QAOA+** algorithm to solve the **Minimum Exact Cover Problem (MECP)** for selected instances. The key steps are:\n",
    "\n",
    "1. **Create Output Folder**: A directory named `parameter_fixing_{current_datetime}` is created to store output files.\n",
    "2. **Iterate Over Instances**: For each instance:\n",
    "   - Define the instance, calculate Exact Covers (EC), and Minimum Exact Covers (MEC).\n",
    "   - Prepare quantum circuits for the problem instance (cost and mixing).\n",
    "   - Initialize QAOA+ with `init_string`\n",
    "3. **Initialize QAOA+ angles**: use parameters fixing technique to initialize angles.\n",
    "4. **Run QAOA+**: Optimize parameters (`beta`, `gamma`) for each layer (`p`), running QAOA+ `random_attempts` times.\n",
    "5. **Post-Processing and Saving**: The best results of each layer are aggregated, saved in `.csv` and `.txt`  files, and a histogram is plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d@%Hh%Mm%Ss\")\n",
    "\n",
    "\n",
    "# Create a  directory where to collect files\n",
    "folder_path = f\"parameter_fixing_{current_datetime}\"\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "\n",
    "# Run QAOA+ for every instance.\n",
    "for instance in chosen_instances:\n",
    "    if chosen_k!= 1:\n",
    "        h = k_dict_new[chosen_k][instance-1]\n",
    "    else:\n",
    "        h = 1\n",
    "    print(\"*\"*50)\n",
    "    print(f\"Instance {instance} with h = {h}\\n\")\n",
    "\n",
    "    FILENAME_list = [] # list of .csv containing the final histograms data.\n",
    "    DATA_FILENAME_list = [] # list of .txt containing metadata such as energies, betas, gammas.\n",
    "\n",
    "    \n",
    "    # Define the instance.\n",
    "    U, subsets_dict = define_instance(n, instance, verbose=False)\n",
    "    subsets = list(subsets_dict.values())\n",
    "    _, _, _, _, EXACT_COVERS = find_spectrum(U, subsets_dict, n, h)\n",
    "    MEC = [state for state in EXACT_COVERS if state.count(\"1\") == min([x.count(\"1\")  for x in EXACT_COVERS])]\n",
    "    \n",
    "    \n",
    "    # Plot states vs energy.\n",
    "    show_spectrum(n, instance, h, fontsize=10)\n",
    "\n",
    "    \n",
    "    # Choose the initialization.\n",
    "    if init_string == 'all1':\n",
    "        # Only \"1\"-states.\n",
    "        init_name = [\"\".join(elem) for elem in distinct_permutations('0'*(n-1) + '1')]\n",
    "\n",
    "    elif init_string == 'all0':\n",
    "        init_name = [\"000000\"]\n",
    "        \n",
    "      \n",
    "    # Prepare the cost and mixing circuit.\n",
    "    constant, hamiltonian, qc_cost = build_cost_circuit(n, instance, h, verbose=False)\n",
    "    qc_mixing = build_mixing_circuit(n, instance, verbose=False)    \n",
    "    qc_initial, check_counts  = build_initialization_circuit(n, instance, init_name, verbose=False)\n",
    "    \n",
    "    # # Check that initialization was correct.\n",
    "    # plot_histogram(check_counts, ax=plt.subplots()[1], title=\"Initialization check\", color='k')\n",
    "    # plt.show(block=False) # don't stop execution\n",
    "    \n",
    "    \n",
    "    # Set initial angles.\n",
    "    gamma_bound = find_gamma_bound(n, instance, h, verbose=False)\n",
    "    \n",
    "    beta_0 = (0, 2*np.pi)\n",
    "    gamma_0 =  (-gamma_bound, gamma_bound)\n",
    "    string_0 = f\"[0,2pi]x[-{gamma_bound},{gamma_bound}]\"\n",
    "    \n",
    "    bnds_beta = (0, 2*np.pi)\n",
    "    bnds_gamma = (-gamma_bound, gamma_bound)\n",
    "    bnds_string = f\"[0,2pi]x[-{gamma_bound},{gamma_bound}]\"\n",
    "    \n",
    "\n",
    "    # Build files' names.\n",
    "    header = f\"dim{n}_mail{instance}_{init_string}\" \\\n",
    "           + f\"_p{max_p}_{random_attempts}ra_k{h}\" \\\n",
    "           + f\"_BOUNDS{bnds_string}_pars0{string_0}\"\n",
    "\n",
    "    DATA_FILENAME = os.path.join(folder_path, header + '_data.txt')\n",
    "    DATA_FILENAME_list.append(DATA_FILENAME)\n",
    "    \n",
    "    \n",
    "    # Collect information in one data-file.\n",
    "    with open(DATA_FILENAME, 'a') as DATA_FILE:\n",
    "        DATA_FILE.write(f\"current datetime = {current_datetime}\")\n",
    "        DATA_FILE.write(f\"The initial state is an equal superposition of: {init_name} \\n\")\n",
    "        DATA_FILE.write(f\"max_p = {max_p}\\n\")\n",
    "        DATA_FILE.write(f\"Random attempts for each layer: {random_attempts}\\n\")\n",
    "\n",
    "        Energies = []\n",
    "        list_df_best = []\n",
    "        TOTAL_start_time = time.time()\n",
    "    \n",
    "        # Increase the number of layers step-by-step.\n",
    "        for p in range(1, max_p+1):\n",
    "        \n",
    "            print(f\"\\n****************** p = {p} ******************\")\n",
    "            pth_start_time = time.time()\n",
    "            E_best = 100\n",
    "            Energies_of_layer_p = []\n",
    "            \n",
    "            for attempt in range(1,random_attempts+1):\n",
    "                print(f\"---------- {attempt}/{random_attempts} random attempts ----------\")\n",
    "                DATA_FILE.write(f\"\\n---------- {attempt}/{random_attempts} random attempts ----------\\n\")\n",
    "    \n",
    "                # Build QAOAAnsatz.\n",
    "                cost_vs_iteration = [] # to save (and plot) iterations\n",
    "                ansatz = QAOAAnsatz(qc_cost, \n",
    "                                    mixer_operator=qc_mixing, \n",
    "                                    initial_state=qc_initial, \n",
    "                                    reps=p, name='QAOA+')\n",
    "        \n",
    "                # Generate a pass manager without providing a backend.\n",
    "                pm = generate_preset_pass_manager(optimization_level=3)\n",
    "                ansatz_isa = pm.run(ansatz)\n",
    "                hamiltonian_isa = hamiltonian.apply_layout(ansatz_isa.layout)\n",
    "            \n",
    "                estimator = StatevectorEstimator()\n",
    "                sampler = StatevectorSampler()\n",
    "            \n",
    "                \n",
    "                # *************************  FIND OPTIMAL ANGLES  ***************************\n",
    "                # *************************     THROUGH QAOA+     ***************************\n",
    "                \n",
    "                # Set initial angles and angles'bounds.\n",
    "                if p == 1:\n",
    "                    pars_0 = [random.uniform(*beta_0)] + [random.uniform(*gamma_0)]  \n",
    "                else:\n",
    "                    pars_0 =  pth_betas + [random.uniform(*beta_0)] + pth_gammas + [random.uniform(*gamma_0)]  \n",
    "                \n",
    "                bnds = [bnds_beta]*p + [bnds_gamma]*p\n",
    "                \n",
    "                print(f\"pars_0 = {pars_0}\")\n",
    "                print(f\"bnds = {bnds}\")\n",
    "                \n",
    "                \n",
    "                # Do the minimization.\n",
    "                result = minimize(cost_func, # change cost_func -> cost_func_plot to plot iterations\n",
    "                                  pars_0, bounds=bnds, \n",
    "                                  args=(ansatz_isa, hamiltonian_isa, estimator), \n",
    "                                  method=\"Nelder-Mead\", \n",
    "                                  options={\"disp\": True, \"maxiter\": 1200, \"maxfev\": 1200}, tol=1e-4)\n",
    "                \n",
    "                \n",
    "                # Works only if you chose cost_func_plot.\n",
    "                if cost_vs_iteration != []:\n",
    "                    plt.figure()\n",
    "                    plt.plot(cost_vs_iteration) \n",
    "                    plt.xlabel(\"Iteration\")\n",
    "                    plt.ylabel(\"Cost\")\n",
    "                    plt.show()\n",
    "                    \n",
    "                    \n",
    "                # Minimum energy reached with minimization.\n",
    "                E_min = result.fun + constant\n",
    "                print(f\"E_min = result.fun + constant = {E_min}\")\n",
    "                print(f\"E_min = result.fun = {result.fun}\")\n",
    "                DATA_FILE.write(f\"\\nE_min = {E_min}\")\n",
    "                Energies_of_layer_p.append(E_min)\n",
    "            \n",
    "            \n",
    "                # Optimal parameters (betas, gammas) found.\n",
    "                betas = list(result.x[:p])\n",
    "                gammas = list(result.x[p:])\n",
    "                print(f\"\\nOptimal parameters: betas, gammas = {betas}, {gammas}\")\n",
    "                DATA_FILE.write(f'\\nE_min\\'s parameters: betas = {betas}, gammas = {gammas}\\n')\n",
    "        \n",
    "                \n",
    "                # Update the best attempt.\n",
    "                if E_min < E_best:\n",
    "                    E_best = E_min\n",
    "#                     d_best = d\n",
    "                    betas_best = betas\n",
    "                    gammas_best = gammas\n",
    "                    best_attempt = attempt\n",
    "                    print(\"--> ***UPDATING THE BEST ATTEMPT***\\n\")\n",
    "                else:\n",
    "                    print(\"--> ***NOT UPDATING THE BEST ATTEMPT***\\n\")\n",
    "                    \n",
    "                    \n",
    "                # ****************************  RUN THE CIRCUIT  ******************************\n",
    "                # ************************ WITH OPTIMAL PARAMETERS ****************************\n",
    "\n",
    "                # Assign to the previously created ansatz the 2p parameters found.\n",
    "                pars = betas + gammas \n",
    "                qc = ansatz.assign_parameters(pars)\n",
    "                qc.measure_all() # add a measurement\n",
    "\n",
    "                # Run this circuit.\n",
    "                qc_isa = pm.run(qc)\n",
    "                output = sampler.run([qc_isa], shots=1024).result()\n",
    "                samp_dist = output[0].data.meas.get_counts()\n",
    "           \n",
    "                \n",
    "                # ****************************  POST PROCESS  **********************************\n",
    "                # *********************** AND SAVE THE OUTPUT HISTOGRAM ************************\n",
    "            \n",
    "                # Create a dataframe from the sampling results.\n",
    "                df = pd.DataFrame(samp_dist.items(), columns=['states', 'counts'])\n",
    "\n",
    "                # Remove ancillary bits.\n",
    "                num_ancillas = get_circuit_parameters(subsets, verbose=False)[2]\n",
    "                df['states'] = df['states'].apply(lambda x: x[num_ancillas:]) \n",
    "\n",
    "                # Invert the bit order for the states (e.g., convert \"01101\" to \"10110\").\n",
    "                df['states'] = df['states'].apply(lambda s: str(s)[::-1])  # Invertiamo l'ordine dei bit\n",
    "\n",
    "                # After removing the ancillary bits, we aggregate counts by state.\n",
    "                df = df.groupby(['states']).sum().reset_index()\n",
    "\n",
    "                # Sort in decreasing order.\n",
    "                df = df.sort_values('counts', ascending=False) \n",
    "\n",
    "                # Rename the \"counts\" column to include attempt details.\n",
    "                df.columns = ['states', f'counts_p{p}_{attempt}of{random_attempts}']\n",
    "\n",
    "                # Merge the current attempt dataframe with previously built dataframes.\n",
    "                if attempt == 1:\n",
    "                    df_all_attempts = df\n",
    "                else:\n",
    "                    df_all_attempts = pd.merge(df_all_attempts, df, on=\"states\", how=\"outer\")    \n",
    "               \n",
    "            # *********************************************************************************\n",
    "    \n",
    "            Energies.append(Energies_of_layer_p)\n",
    "            DATA_FILE.write(f\"\\n----- p = {p} layer -----\\nMinimum energy found in each attempt: \")\n",
    "            DATA_FILE.write(str(Energies_of_layer_p))\n",
    "            \n",
    "            print(f\"E_best = {E_best}\")\n",
    "            DATA_FILE.write(f\"\\nE_best = {E_best}\")\n",
    "            \n",
    "            \n",
    "            # Plot the best attempt (minimum energy), with error bars\n",
    "            # representing other attempts in the global dataframe.\n",
    "            plot_histogram_of_best_column(df_all_attempts, \n",
    "                                          f'counts_p{p}_{best_attempt}of{random_attempts}', \n",
    "                                          EXACT_COVERS, init_name,\n",
    "                                          fontsize=12, \n",
    "                                          title=f\"Result (best attempt) for instance {instance}, layer p={p}\")\n",
    "\n",
    "            # Collect.\n",
    "            df_best = df_all_attempts[['states', f'counts_p{p}_{best_attempt}of{random_attempts}']]\n",
    "            df_best.columns = ['states', f'counts_p{p}'] # rename the second column\n",
    "            list_df_best.append(df_best)\n",
    "            \n",
    "            \n",
    "            # Best parameters'vector of length 2p found for the p-th layer\n",
    "            pth_betas = betas_best\n",
    "            pth_gammas = gammas_best\n",
    "            \n",
    "            print(f'\\nE_best\\'s parameters: betas = {pth_betas}, gammas = {pth_gammas}\\n')\n",
    "            print(\"Execution time of p={0} layer: {1:.1f} min\".format(p, (time.time() - pth_start_time)/60))\n",
    "            DATA_FILE.write(f'\\nE_best\\'s parameters: betas = {pth_betas}, gammas = {pth_gammas}\\n')\n",
    "            DATA_FILE.write(\"Execution time of p={0} layer: {1:.1f} min\\n\".format(p, (time.time() - pth_start_time)/60))\n",
    "\n",
    "\n",
    "        # Merge DataFrames\n",
    "        df_final = reduce(lambda left, right: pd.merge(left, right, on='states', how='outer'), list_df_best)\n",
    "        df_final = df_final.fillna(0) # missing values -> 0\n",
    "        df_final = df_final.sort_values(by=f'counts_p{max_p}').reset_index(drop=True)\n",
    "\n",
    "        # Save to csv\n",
    "        FILENAME = os.path.join(folder_path, header + f\".csv\")\n",
    "        df_final.to_csv(FILENAME, index=False)\n",
    "        \n",
    "        # ************************ SEE FINAL RESULT ************************\n",
    "        # Plot all the dataframes in one picture.\n",
    "        plt.figure()\n",
    "        plt.rcParams['font.size'] = 10\n",
    "        df_final = df_final.fillna(0)\n",
    "        df_final = df_final.sort_values(f'counts_p{max_p}', ascending=False) \n",
    "        df_final.plot(x='states', kind=\"bar\", figsize=(8,4), stacked=False)\n",
    "\n",
    "        # Make labels with percentages (only for the last layer).\n",
    "        ax1 = plt.gca()\n",
    "        ax1.set_ylabel(\"counts\")\n",
    "        to_percentage = lambda x: (x/df_final[f'counts_p{max_p}'].sum())*100\n",
    "        labels = df_final[f'counts_p{max_p}'].apply(to_percentage).round(1).astype('str') + '%'\n",
    "        ax1.bar_label(ax1.containers[-1], labels=labels)\n",
    "\n",
    "        highlight_correct_ticks(plt.gca(), EXACT_COVERS)\n",
    "        plt.legend(labels=[f'counts p={p}' for p in range (1, max_p+1)])\n",
    "        plt.minorticks_on()\n",
    "        plt.grid(alpha=0.2, which='both')\n",
    "        plt.ylim(0,1024)\n",
    "        plt.title(f\"Instance {instance}\")\n",
    "        \n",
    "        print(f\"\\nTOTAL ELAPSED TIME: {(time.time() - TOTAL_start_time)/60} minutes.\")\n",
    "        DATA_FILE.write(f\"\\nTOTAL ELAPSED TIME: {(time.time() - TOTAL_start_time)/60} minutes.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Read from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uncomment this line to plot data from an existing directory\n",
    "folder_path = \"./parameter_fixing_2025-01-30@10h22m24s/\"\n",
    "files, datafiles = find_files_containing_string(path=folder_path, verbose=True)\n",
    "\n",
    "l = len(datafiles)\n",
    "if l > 1:\n",
    "    # Plot the whole list of files found.\n",
    "    plot_list_of_files_parameter_fixing(datafiles, files,\n",
    "                                        dont_show_in_title=[\"i\", \"k\"], \n",
    "                                        dont_show_in_titles=[\"n\", \"init\", \"p\", \"ra\"], \n",
    "                                        figsize=(10, l+2), N=10, dpi=100, show_title=True)\n",
    "else:\n",
    "    plot_file_parameter_fixing(datafiles[0], files[0],\n",
    "                               show_title=True,\n",
    "                               figsize=(8, 4), N=10, dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
